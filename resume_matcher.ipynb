{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9df7ad3a-025d-4f68-83e5-c9a34106a725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume Match Score: 30.81%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Reading the resume and job description\n",
    "with open(\"data/sreehari_resume.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    resume = f.read()\n",
    "\n",
    "with open(\"data/data_scientist_jd.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    job_description = f.read()\n",
    "\n",
    "#  Creating TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform([resume, job_description])\n",
    "\n",
    "\n",
    "similarity_matrix = cosine_similarity(vectors[0:1], vectors[1:2])\n",
    "match_score = similarity_matrix[0][0] * 100  \n",
    "\n",
    "# Getting the result\n",
    "print(f\"Resume Match Score: {match_score:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca67e59-edc2-4f7c-b416-731a73ac14b7",
   "metadata": {},
   "source": [
    "## Multiple resumes vs one jd (real time example) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e09ede7-226c-4b66-9720-12339957cb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "data_folder = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e40065e-34bf-468e-931a-8c984bfd1c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_folder, \"data_scientist_jd.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    jd_text = f.read()\n",
    "\n",
    "resume_scores = []\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith(\".txt\") and filename != \"data_scientist_jd.txt\":\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            resume_text = f.read()\n",
    "\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectors = vectorizer.fit_transform([resume_text, jd_text])\n",
    "        similarity = cosine_similarity(vectors[0:1], vectors[1:2])[0][0] * 100\n",
    "\n",
    "        resume_scores.append((filename, round(similarity, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8973ef01-f907-43f0-a86d-8d7df81a0c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resume_3.txt : 45.32% match\n",
      "resume_1.txt : 44.69% match\n",
      "resume_2.txt : 41.93% match\n",
      "sreehari_resume.txt : 14.58% match\n"
     ]
    }
   ],
   "source": [
    "sorted_scores = sorted(resume_scores, key=lambda x: x[1], reverse=True)\n",
    "for file, score in sorted_scores:\n",
    "    print(f\"{file} : {score}% match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe894de5-72b0-495c-82ad-8182dff199d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Folder containing your data\n",
    "data_folder = \"data\"\n",
    "\n",
    "# Step 1: Read the Job Description\n",
    "with open(os.path.join(data_folder, \"data_scientist_jd.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    jd_text = f.read()\n",
    "\n",
    "# Step 2: Load all resume files\n",
    "resume_scores = []\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith(\".txt\") and filename != \"data_scientist_jd.txt\":\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            resume_text = f.read()\n",
    "        \n",
    "        # Step 3: Vectorize JD and Resume\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectors = vectorizer.fit_transform([resume_text, jd_text])\n",
    "        similarity = cosine_similarity(vectors[0:1], vectors[1:2])[0][0] * 100\n",
    "        \n",
    "        # Store the results\n",
    "        resume_scores.append((filename, round(similarity, 2)))\n",
    "\n",
    "# Step 4: Sort and Display\n",
    "sorted_scores = sorted(resume_scores, key=lambda x: x[1], reverse=True)\n",
    "for file, score in sorted_scores:\n",
    "    print(f\"{file}: {score}% match\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c56cdb4-b58a-4271-bc4f-f2c602aafa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"resume_match_scores.csv\", \"w\", newline = \"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Resume File\", \"Match Score (%)\"])\n",
    "    for file, score in sorted_scores:\n",
    "        writer.writerow([file, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a981d77d-7d36-407f-98c4-334b848b9565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d50e499d-69ba-4c86-92c2-eda9b79fe188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Keywords Missing from Resume:\n",
      "['build', 'business', 'cases', 'checks', 'chennai', 'client', 'collaborate', 'conduct', 'contribute', 'datasets']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# 1. Vectorize with simple word counts\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "cv_matrix = cv.fit_transform([jd_text, resume_text])\n",
    "\n",
    "# 2. Get feature names (words)\n",
    "words = cv.get_feature_names_out()\n",
    "\n",
    "# 3. Convert to array to count frequency\n",
    "counts = cv_matrix.toarray()\n",
    "\n",
    "# 4. Find words in JD (row 0) but not in Resume (row 1)\n",
    "jd_word_counts = counts[0]\n",
    "resume_word_counts = counts[1]\n",
    "\n",
    "missing_keywords = []\n",
    "for idx, (jd_count, resume_count) in enumerate(zip(jd_word_counts, resume_word_counts)):\n",
    "    if jd_count > 0 and resume_count == 0:\n",
    "        missing_keywords.append(words[idx])\n",
    "\n",
    "# 5. Show top 10 missing keywords\n",
    "print(\"\\nTop Keywords Missing from Resume:\")\n",
    "print(missing_keywords[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97063379-2a34-454a-a0e4-292d97a08c31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d5130-8db2-4fad-a17e-daf32f74a6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6977d6-9c14-416a-888b-3bfe326c2160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af39ead-2e29-419c-9322-a6d60557e352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c90ee1d-cec7-4e3e-98e3-10b0b67f1a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9311bc1c-6c31-48e7-8f91-5414ef9e6086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe96a66-7d26-49cb-bc33-2142946fe555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c852370a-5baf-41fe-a0fa-fcc018ccb5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc75bb1-d0b9-4c5a-9154-4045e1cab88f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a0988-a2fd-400f-91e3-164c89942383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0794801b-a5fe-4150-842c-fa4a1c580b24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d972ce05-3dbb-41cf-ba6f-d309ff6bc339",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
